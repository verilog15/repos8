# Whether to use the HuggingFace API or Ollama
# Set this to yes or no
USE_HUGGINGFACE=

# This token is optional but you'll have more restrictive rate limits and model options without it
# Get your HuggingFace token from https://huggingface.co/settings/tokens
HUGGINGFACE_API_TOKEN=

# The model ID to use from HuggingFace for the reasoning LLM. 
# Get this by visiting the model page on HuggingFace and copying the ID in the URL or in the top left of the page
# Example: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
REASONING_MODEL_ID=

# The model ID to use from HuggingFace for the tool calling LLM
# Example: meta-llama/Llama-3.3-70B-Instruct
TOOL_MODEL_ID=
